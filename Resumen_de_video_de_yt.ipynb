{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgH68V+pwB1MNYjGP6eMVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoCaz/Resumen_video_yt/blob/main/Resumen_de_video_de_yt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rkSxK6139QaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb78d28-7b11-4547-ff3a-a18ad403120d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-2cfq97ln\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-2cfq97ln\n",
            "  Resolved https://github.com/openai/whisper.git to commit ad3250a846fe7553a25064a2dc593e492dadf040\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230308) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230308) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230308) (1.22.4)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230308) (0.56.4)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230308) (9.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230308) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230308) (3.9.0)\n",
            "Collecting lit\n",
            "  Downloading lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230308) (3.22.6)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.19.0->openai-whisper==20230308) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.19.0->openai-whisper==20230308) (23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.19.0->openai-whisper==20230308) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers>=4.19.0->openai-whisper==20230308) (2.25.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230308) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230308) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230308) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230308) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230308) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230308) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230308) (4.0.0)\n",
            "Building wheels for collected packages: openai-whisper, lit\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230308-py3-none-any.whl size=1187494 sha256=7dec11eeb9d04745a41a598c0718697f4e9d7fff87d3a7521077edab3055deaf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rzoghq6y/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=90004 sha256=e5908ec540475053339048a788c711ae8e2f28be00d47860c83603d8f8f97d99\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/68/18/2ad49b416abb9139c8217c349fd9df0674da8f0d1952db2ea5\n",
            "Successfully built openai-whisper lit\n",
            "Installing collected packages: tokenizers, lit, ffmpeg-python, triton, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.13.0 lit-15.0.7 openai-whisper-20230308 tokenizers-0.13.2 transformers-4.26.1 triton-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package 'youtube-dl' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,015 kB]\n",
            "Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,539 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,310 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,014 kB]\n",
            "Fetched 8,218 kB in 3s (2,854 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "30 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install pytube\n",
        "!sudo apt-get remove -y youtube-dl\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte del codigo donde se descarga el video de youtube"
      ],
      "metadata": {
        "id": "gQy-7CSw5Qib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "\n",
        "#Cambia el link que quieras\n",
        "LINK = \"https://www.youtube.com/watch?v=4bxpsvcW2mc&t=480s&ab_channel=ElizabethFilips\"\n",
        "\n",
        "# Obtener objeto YouTube\n",
        "yt = YouTube(LINK)\n",
        "\n",
        "# Obtener objeto Stream de audio\n",
        "audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "\n",
        "# Descargar archivo de audio en una ubicación temporal\n",
        "temp_file_path = audio_stream.download()\n",
        "\n",
        "# Renombrar archivo a \"audio.mp3\" y mover a la carpeta actual\n",
        "os.rename(temp_file_path, os.path.join(os.getcwd(), \"audio.mp3\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "BaBmSM8KAj7p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"audio.mp3\")"
      ],
      "metadata": {
        "id": "BPVV8FNIfFaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc1d269d-22fb-45e6-f235-bd4b0da2df36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 58.6MiB/s]\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nombre_archivo = \"texto_original.txt\"\n",
        "\n",
        "with open(nombre_archivo, \"w\") as archivo:\n",
        "    archivo.write(result[\"text\"])\n",
        "\n",
        "# Cerrar el archivo\n",
        "archivo.close()"
      ],
      "metadata": {
        "id": "i6RKnwL8gbAN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte del codigo donde se genera el resumen"
      ],
      "metadata": {
        "id": "EPPV4rit5ZeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install urllib3\n",
        "!pip install nltk\n",
        "!python -m nltk.downloader punkt\n",
        "!python -m nltk.downloader stopwords"
      ],
      "metadata": {
        "id": "1Siu_kLci2qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b935bf-b2b4-4f4e-c284-99d3662ff3e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (1.26.14)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "/usr/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs  \n",
        "import urllib.request  \n",
        "import re\n",
        "import nltk\n",
        "from nltk import word_tokenize,sent_tokenize\n",
        "import heapq  \n"
      ],
      "metadata": {
        "id": "TiQKxRbWmUNa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tamaño del resumen, cuando mas grande el numero mas extenso el resumen\n",
        "tamanio_resumen = 150\n",
        "\n",
        "# Función para formatear el artículo\n",
        "def formatear_articulo(texto):\n",
        "    texto_formateado = re.sub('[^a-zA-Z]', ' ', texto)\n",
        "    texto_formateado = re.sub(r'\\s+', ' ', texto_formateado)\n",
        "    return texto_formateado\n",
        "\n",
        "# Función para calcular la frecuencia de palabras\n",
        "def calcular_frecuencia_palabras(texto_formateado):\n",
        "    palabras = nltk.word_tokenize(texto_formateado.lower())\n",
        "    stopwords = nltk.corpus.stopwords.words('spanish')\n",
        "    frecuencia_palabras = {word: palabras.count(word) for word in palabras if word not in stopwords}\n",
        "    return frecuencia_palabras\n",
        "\n",
        "# Función para obtener las oraciones\n",
        "def obtener_oraciones(texto):\n",
        "    return nltk.sent_tokenize(texto)\n",
        "\n",
        "# Función para calcular la frecuencia de las oraciones\n",
        "def calcular_frecuencia_oraciones(oraciones, frecuencia_palabras):\n",
        "    max_oracion = {}\n",
        "    for sent in oraciones:\n",
        "        for word in nltk.word_tokenize(sent.lower()):\n",
        "            if word in frecuencia_palabras.keys():\n",
        "                if len(sent.split(' ')) < tamanio_resumen:\n",
        "                    if sent not in max_oracion.keys():\n",
        "                        max_oracion[sent] = frecuencia_palabras[word]\n",
        "                    else:\n",
        "                        max_oracion[sent] += frecuencia_palabras[word]\n",
        "    return max_oracion\n",
        "\n",
        "# Función para generar el resumen\n",
        "def generar_resumen(texto):\n",
        "    texto_formateado = formatear_articulo(texto)\n",
        "    frecuencia_palabras = calcular_frecuencia_palabras(texto_formateado)\n",
        "    oraciones = obtener_oraciones(texto)\n",
        "    max_oracion = calcular_frecuencia_oraciones(oraciones, frecuencia_palabras)\n",
        "    resumen_oracion = heapq.nlargest(7, max_oracion, key=max_oracion.get)\n",
        "    resumen = ' '.join(resumen_oracion)\n",
        "    return resumen\n",
        "\n",
        "\n",
        "resumen = generar_resumen(result[\"text\"])\n",
        "print(resumen)\n",
        "\n",
        "\n",
        "nombre_archivo = \"salida.txt\"\n",
        "\n",
        "with open(nombre_archivo, \"w\") as archivo:\n",
        "    archivo.write(resumen)\n",
        "\n",
        "# Cerrar el archivo\n",
        "archivo.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8k2Rp22qvUG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a620ce-a500-43f7-c70a-cb3db20d7c67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Then I'll have art, so sometimes if I see like getting to know yourself, if there's some relevant art that I find or nine, which is quite inspiring, I will try to get a resource, I don't have a resource for this, but and I will put it there because if I need to talk about it, I might link the art to it too. I honestly find this so, so useful because it means that every single book that I read, I analyse so much and I spent a lot of time kind of connecting to previous things that I know and previous things that I found and really thinking, is this relevant to my life? So every time I create a note, I will go all the way to my second brain and look through every single one on my list and think, oh, this is slightly relevant, so this could be a secondary source on something, it could be a tertiary source on something, it could be a primary source on something else, and this is how I keep populating my second brain with very interesting connections to me that were not there previously. To start with, you might just start with topics themselves, so like life and history and geography and things that you personally find interesting, but as soon as you come up with a theme, branch that into a theme, and as soon as you get an interesting concept within that theme, I would recommend putting that concept as its own separate category, because as soon you break into categories, the sooner every time that you want to put a draft in, you can think, oh, this would fit here and there. So for example, if someone asks me what are some studies about getting to know yourself, I probably will have a few studies that will be relevant to it already, and I don't need to go and search for them in the tens of tens of things that I have put in my primary source. I have had some variation of a second brain for over a decade now, so it comes very naturally to me when I am consuming things like books or articles or podcasts, to kind of think in the back of my mind, what do I not want to forget here, what do I want to store. Number two is because it helps me make connections on things that I would not have necessarily done without it, and whenever I have to work on a project or write things, I already have a pre-set up library of my own thoughts, which is perfect and timeless, and does not fade the way that my natural memory does.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIqBcuBhYzBf",
        "outputId": "b9005cce-0684-4bdc-d3a2-3ffb1b7c3e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "# cargar modelo y tokenizador\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# definir texto de entrada\n",
        "input_text = result[\"text\"]\n",
        "max_input_length = model.config.max_position_embeddings - 2 # tomar en cuenta los tokens especiales [CLS] y [SEP]\n",
        "if len(input_text) > max_input_length:\n",
        "    # segmentar el texto\n",
        "    input_segments = [input_text[i:i+max_input_length] for i in range(0, len(input_text), max_input_length)]\n",
        "else:\n",
        "    input_segments = [input_text]\n",
        "\n",
        "# definir preguntas\n",
        "questions = [\n",
        "   \"¿De qué se está hablando en el texto?\"\n",
        "]\n",
        "\n",
        "# hacer inferencia y mostrar resultados\n",
        "for q in questions:\n",
        "    response_segments = []\n",
        "    for segment in input_segments:\n",
        "        input_sequence = f\"{segment.strip()} {tokenizer.sep_token} {q}\"\n",
        "        input_ids = tokenizer.encode(input_sequence, add_special_tokens=True)\n",
        "        max_length = model.config.max_position_embeddings - input_ids.size(1) # establecer la longitud máxima en función del tamaño máximo de posición del modelo\n",
        "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long) # crear la máscara de atención\n",
        "        outputs = model.generate(input_ids, max_length=max_length, do_sample=True, pad_token_id=model.config.eos_token_id, \n",
        "                                 attention_mask=attention_mask) # generar la respuesta\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        response_segments.append(response)\n",
        "\n",
        "    # concatenar las respuestas de los segmentos\n",
        "    response = \" \".join(response_segments)\n",
        "\n",
        "    print(f\"Pregunta: {q}\")\n",
        "    print(f\"Respuesta: {response}\\n\")\n"
      ],
      "metadata": {
        "id": "AjlS07mDgeCc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}